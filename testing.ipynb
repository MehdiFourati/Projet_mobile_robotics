{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import keyboard\n",
    "import time\n",
    "\n",
    "import Controlling_thymio\n",
    "import global_planning\n",
    "import vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angle:[2.65711472]\n",
      "[[(np.int32(440), np.int32(313)), (np.int32(344), np.int32(266)), (np.int32(372), np.int32(141))], [(np.int32(295), np.int32(140)), (np.int32(193), np.int32(281)), (np.int32(18), np.int32(128))]]\n",
      "['R', 'P2', 'P4', 'G']\n"
     ]
    }
   ],
   "source": [
    "# Vision example on an image\n",
    "\n",
    "# load the image\n",
    "img = cv.imread(\"testing_vision.jpg\")\n",
    "img = cv.resize(img, (640,480), interpolation=cv.INTER_CUBIC) \n",
    "\n",
    "# do the actual vision\n",
    "original_coordinates, new_coordinates = vision.get_fop_coordinates(img)\n",
    "fop = vision.get_fop(img, original_coordinates, new_coordinates)\n",
    "start_x, start_y, alpha, width = vision.get_starting_position(fop)\n",
    "obstacles = vision.get_obstacles(fop,width)\n",
    "objective_x, objective_y = vision.get_objective(fop)\n",
    "\n",
    "# draws everything and displays it\n",
    "output = fop.copy()\n",
    "cv.circle(output, (objective_x, objective_y), radius=10, color=(255, 0, 0), thickness=-1)\n",
    "cv.circle(output, (start_x, start_y), radius=10, color=(0, 0, 255), thickness=-1)\n",
    "for obstacle in obstacles:\n",
    "    for vertice in obstacle:\n",
    "        cv.circle(output, (vertice[0],vertice[1]), radius=10, color=(0, 255, 0), thickness=-1)\n",
    "\n",
    "print(\"Angle:\" + str(alpha))\n",
    "\n",
    "converted_data = [[tuple(arr) for arr in sublist] for sublist in obstacles]\n",
    "print(converted_data)\n",
    "\n",
    "converted_data = global_planning.obstacle_dictionnary(converted_data)\n",
    "robot_instance = global_planning.Robot()\n",
    "goal = (objective_x,objective_y)\n",
    "\n",
    "robot_instance.update_coordinates(start_x, start_y, alpha,width)\n",
    "obstacles_named = global_planning.naming_points(converted_data,robot_instance,goal)\n",
    "adg_list = global_planning.creating_adjacency_dictionnary(converted_data,robot_instance,goal)\n",
    "path = global_planning.finding_path(adg_list,obstacles_named)\n",
    "print(path)\n",
    "for i in range(len(path[:-1])):\n",
    "    cv.line(output,(obstacles_named[path[i]][0],obstacles_named[path[i]][1]),(obstacles_named[path[i+1]][0],obstacles_named[path[i+1]][1]),(255,0,0),5)\n",
    "    \n",
    "\n",
    "cv.imshow(\"image\", output)\n",
    "\n",
    "# press any key to close all windows\n",
    "cv.waitKey(0) \n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the rectangular frame:\n",
      "580.0 369.0\n",
      "Starting coordinates and angle:\n",
      "(x ,y, alpha) = 533, 48, [2.65711472]\n",
      "Robot width:\n",
      "62\n",
      "Vertices of the obstacles:\n",
      "[[array([502, 134], dtype=int32), array([433, 312], dtype=int32), array([344, 269], dtype=int32), array([372, 140], dtype=int32)], [array([299, 138], dtype=int32), array([193, 281], dtype=int32), array([ 21, 141], dtype=int32), array([18, 92], dtype=int32)]]\n",
      "Goal coordinates:\n",
      "42 324\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensions of the rectangular frame:\")\n",
    "print(new_coordinates[3][0], new_coordinates[3][1])\n",
    "\n",
    "print(\"Starting coordinates and angle:\") # angle of the robot relative to the x axis, counterclockwise, expressed in radian in range (-pi, pi]\n",
    "print(\"(x ,y, alpha) = \" + str(start_x) + \", \"+ str(start_y) + \", \" + str(alpha))\n",
    "\n",
    "print(\"Robot width:\")\n",
    "print(width)\n",
    "\n",
    "print(\"Vertices of the obstacles:\")\n",
    "print(obstacles)\n",
    "\n",
    "print(\"Goal coordinates:\")\n",
    "print(objective_x, objective_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global constants here\n",
    "\n",
    "# width of the video feed\n",
    "IMAGE_WIDTH = 640\n",
    "# height of the video feed\n",
    "IMAGE_HEIGHT = 480\n",
    "# fps of the video feed\n",
    "CAMERA_FPS = 30\n",
    "# keyboard input to start\n",
    "KEYBOARD_INPUT = \"enter\"\n",
    "# number of frame thrown away to allow the camera to focus in the meantime\n",
    "CAMERA_REFRESH_TIME = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R', 'P4', 'G']\n",
      "['R', 'P3', 'G']\n",
      "['R', 'P2', 'G']\n",
      "['R', 'P4', 'G']\n",
      "['R', 'P3', 'G']\n",
      "['R', 'P4', 'G']\n",
      "['R', 'P3', 'G']\n",
      "['R', 'P5', 'G']\n",
      "['R', 'P6', 'G']\n",
      "['R', 'P5', 'G']\n",
      "['R', 'P3', 'G']\n",
      "['R', 'P3', 'G']\n",
      "['R', 'P2', 'G']\n",
      "['R', 'P5', 'G']\n",
      "['R', 'P4', 'G']\n",
      "['R', 'P5', 'G']\n",
      "['R', 'P4', 'G']\n",
      "['R', 'P5', 'G']\n",
      "['R', 'P5', 'G']\n"
     ]
    }
   ],
   "source": [
    "# 0 is laptop webcam, 1 is USB camera (!COMPUTER DEPENDENT!)\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "init = False # boolean set to True on keyboard input to start initialisation\n",
    "is_init = False # boolean set to True once initialisation has succeeded\n",
    "black_frame_remaining = 0 # numbers of frames to throw away\n",
    "being_kidnapped = False # boolean set to True while the robot is being kidnapped\n",
    "\n",
    "# variable initialized at False irrelevant of wether it actually is\n",
    "camera_hidden = False\n",
    "\n",
    "# create a robot instance\n",
    "robot_instance = global_planning.Robot()\n",
    "\n",
    "# if unable to connect to the camera\n",
    "if not (cap.isOpened()):\n",
    "    print(\"Could not open video device\")\n",
    "else:\n",
    "    while(True):\n",
    "        # get the input frame by frame (shape (480,640,3))\n",
    "        ret, frame = cap.read() \n",
    "        cap.set(cv.CAP_PROP_FPS, CAMERA_FPS) \n",
    "        frame = cv.resize(frame, (IMAGE_WIDTH,IMAGE_HEIGHT), interpolation=cv.INTER_CUBIC) \n",
    "\n",
    "        # wait until keyboard input to initialize vision\n",
    "        if keyboard.is_pressed(KEYBOARD_INPUT):\n",
    "            init = True\n",
    "\n",
    "        # reinitialize the robot after a kidnapping\n",
    "        if being_kidnapped: \n",
    "            if not Controlling_thymio.kidnapping(node):\n",
    "                \n",
    "                # to give time to the kidnapper to get out of the frame\n",
    "                time.sleep(1)\n",
    "\n",
    "                # reinitialize the starting position of the robot\n",
    "                fop = vision.get_fop(frame, original_coordinates, new_coordinates)\n",
    "                start_x, start_y, alpha, width = vision.get_starting_position(fop)\n",
    "\n",
    "                # reinitialize the global planning\n",
    "                converted_obstacles = [[tuple(arr) for arr in sublist] for sublist in obstacles]\n",
    "                converted_obstacles = global_planning.obstacle_dictionnary(converted_obstacles)\n",
    "                goal = (objective_x, objective_y)\n",
    "                robot_instance.update_coordinates(start_x, start_y, alpha, width)\n",
    "                obstacles_named = global_planning.naming_points(converted_data, robot_instance, goal)\n",
    "                adg_list = global_planning.creating_adjacency_dictionnary(converted_data, robot_instance, goal)\n",
    "                path = global_planning.finding_path(adg_list, obstacles_named)\n",
    "\n",
    "                is_init = True\n",
    "                being_kidnapped = False\n",
    "        \n",
    "        # initialize \n",
    "        if init == True:\n",
    "\n",
    "            try:\n",
    "                # vision: start, obstacles and goal coordinates\n",
    "                original_coordinates, new_coordinates = vision.get_fop_coordinates(frame)\n",
    "                fop = vision.get_fop(frame, original_coordinates, new_coordinates)\n",
    "                start_x, start_y, alpha, width = vision.get_starting_position(fop)\n",
    "                obstacles = vision.get_obstacles(fop, width)\n",
    "                objective_x, objective_y = vision.get_objective(fop)\n",
    "\n",
    "                # global planning\n",
    "                converted_obstacles = [[tuple(arr) for arr in sublist] for sublist in obstacles]\n",
    "                converted_obstacles = global_planning.obstacle_dictionnary(converted_obstacles)\n",
    "                goal = (objective_x,objective_y)\n",
    "                robot_instance.update_coordinates(start_x, start_y, alpha,width)\n",
    "                obstacles_named = global_planning.naming_points(converted_obstacles,robot_instance,goal)\n",
    "                adg_list = global_planning.creating_adjacency_dictionnary(converted_obstacles,robot_instance,goal)\n",
    "                path = global_planning.finding_path(adg_list,obstacles_named)\n",
    "                print(path)\n",
    "                is_init = True\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(\"Initialisation failed\")\n",
    "\n",
    "            init = False\n",
    "\n",
    "        if is_init:  \n",
    "        ################################## CALL FUNCTIONS HERE ################################## \n",
    "            \n",
    "            # get out of the loop if the robot is being kidnapped\n",
    "            \"\"\" if Controlling_thymio.kidnapping(node):\n",
    "                being_kidnapped = True\n",
    "                is_init = False\n",
    "                continue \"\"\"\n",
    "\n",
    "            fop = vision.get_fop(frame, original_coordinates, new_coordinates)\n",
    "            center_x, center_y = vision.get_robot_center(fop)\n",
    "            \n",
    "            # camera was covered, now uncovered\n",
    "            if center_x != 0 and center_y != 0 and camera_hidden:\n",
    "                camera_hidden = False\n",
    "                black_frame_remaining = CAMERA_REFRESH_TIME # to give it time to gain focus\n",
    "\n",
    "            # camera was uncovered, now covered -> navigation using Kalman filter\n",
    "            elif center_x == 0 and center_y == 0:\n",
    "                camera_hidden = True\n",
    "\n",
    "                # DO KALMAN NAVIGATION HERE\n",
    "\n",
    "            # camera uncovered and usable -> navigation using vision\n",
    "            elif black_frame_remaining <= 0:\n",
    "                fop = cv.circle(fop, (center_x,center_y), radius=10, color=(0, 255, 0), thickness=-1)\n",
    "\n",
    "                # DO VISION NAVIGATION HERE\n",
    "                \n",
    "            else:\n",
    "                # set the first frames after uncovering to black to allow time to focus\n",
    "                fop = cv.cvtColor(fop, cv.COLOR_BGR2GRAY)\n",
    "                _, fop = cv.threshold(fop,255,255,cv.THRESH_BINARY)\n",
    "                black_frame_remaining -= 1\n",
    "\n",
    "\n",
    "            # draw everything\n",
    "            if not camera_hidden and black_frame_remaining <= 0:\n",
    "                cv.circle(fop, (objective_x, objective_y), radius=10, color=(255, 0, 0), thickness=-1)\n",
    "                cv.circle(fop, (start_x, start_y), radius=10, color=(0, 0, 255), thickness=-1)\n",
    "                for obstacle in obstacles:\n",
    "                    for vertice in obstacle:\n",
    "                        cv.circle(fop, (vertice[0],vertice[1]), radius=10, color=(0, 255, 0), thickness=-1)\n",
    "                for i in range(len(path[:-1])):\n",
    "                    cv.line(fop,(obstacles_named[path[i]][0],obstacles_named[path[i]][1]),(obstacles_named[path[i+1]][0],obstacles_named[path[i+1]][1]),(255,0,0),5)\n",
    "    \n",
    "\n",
    "        #########################################################################################\n",
    "        else:\n",
    "            # to output the raw feed\n",
    "            fop = frame\n",
    "\n",
    "        cv.imshow('Raw',frame)\n",
    "        cv.imshow('Processed',fop)\n",
    "\n",
    "        await client.sleep(0.001)\n",
    "        \n",
    "        # Close all windows and get out of the loop if ESC is pressed\n",
    "        if cv.waitKey(1) == 27:\n",
    "            cv.destroyAllWindows()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NodeLockError",
     "evalue": "Node lock error (current status: connected)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNodeLockError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mControlling_thymio\u001b[39;00m\n\u001b[0;32m      5\u001b[0m node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m client\u001b[38;5;241m.\u001b[39mwait_for_node()\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m node\u001b[38;5;241m.\u001b[39mlock()\n\u001b[0;32m      8\u001b[0m aw(node\u001b[38;5;241m.\u001b[39mlock())\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m node\u001b[38;5;241m.\u001b[39mwait_for_variables({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n",
      "File \u001b[1;32mc:\\Users\\zalex\\anaconda3\\envs\\MOBILEROBOTS\\Lib\\site-packages\\tdmclient\\clientasyncnode.py:61\u001b[0m, in \u001b[0;36mClientAsyncNode.lock\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     59\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlock_node()\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 61\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NodeLockError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[1;31mNodeLockError\u001b[0m: Node lock error (current status: connected)"
     ]
    }
   ],
   "source": [
    "from tdmclient import ClientAsync, aw\n",
    "client = ClientAsync()\n",
    "import Controlling_thymio\n",
    "\n",
    "node = await client.wait_for_node()\n",
    "\n",
    "await node.lock()\n",
    "aw(node.lock())\n",
    "\n",
    "await node.wait_for_variables({\"acc\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialisation failed: division by zero\n",
      "Initialisation failed: division by zero\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zalex\\AppData\\Local\\Temp\\ipykernel_17264\\174447522.py:64: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  Controlling_thymio.controlling_wheels_speed(int(vl),int(vr),aw,node)\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 61\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_init:  \n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m################################## CALL FUNCTIONS HERE ################################## \u001b[39;00m\n\u001b[0;32m     60\u001b[0m     fop \u001b[38;5;241m=\u001b[39m vision\u001b[38;5;241m.\u001b[39mget_fop(frame, original_coordinates, new_coordinates)\n\u001b[1;32m---> 61\u001b[0m     center_x, center_y, alpha, _ \u001b[38;5;241m=\u001b[39m vision\u001b[38;5;241m.\u001b[39mget_starting_position(fop)\n\u001b[0;32m     62\u001b[0m     robot_instance\u001b[38;5;241m.\u001b[39mupdate_coordinates(center_x,center_y,alpha,width)\n\u001b[0;32m     63\u001b[0m     vl, vr \u001b[38;5;241m=\u001b[39m Controlling_thymio\u001b[38;5;241m.\u001b[39mcompute_wheel_speeds(robot_instance,(obstacles_named[path[\u001b[38;5;241m1\u001b[39m]][\u001b[38;5;241m0\u001b[39m],obstacles_named[path[\u001b[38;5;241m1\u001b[39m]][\u001b[38;5;241m1\u001b[39m]),robot_instance\u001b[38;5;241m.\u001b[39mrobot_width,\u001b[38;5;241m0.05\u001b[39m,\u001b[38;5;241m0.05\u001b[39m,\u001b[38;5;241m0.05\u001b[39m,\u001b[38;5;241m0.02\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\zalex\\Documents\\EPFL\\Master\\Basics of mobile robotics\\Project\\Projet_mobile_robotics\\vision.py:122\u001b[0m, in \u001b[0;36mget_starting_position\u001b[1;34m(frame)\u001b[0m\n\u001b[0;32m    119\u001b[0m     direction_x \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    120\u001b[0m     direction_y \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m y\n\u001b[1;32m--> 122\u001b[0m direction_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(direction_x \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(contours))\n\u001b[0;32m    123\u001b[0m direction_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(direction_y \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(contours))\n\u001b[0;32m    125\u001b[0m \u001b[38;5;66;03m# get the center of the robot\u001b[39;00m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "# 0 is laptop webcam, 1 is USB camera (!COMPUTER DEPENDENT!)\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "init = False # boolean set to True on keyboard input to start initialisation\n",
    "is_init = False # boolean set to True once initialisation has succeeded\n",
    "black_frame_remaining = 0 # numbers of frames to throw away\n",
    "being_kidnapped = False # boolean set to True while the robot is being kidnapped\n",
    "\n",
    "# variable initialized at False irrelevant of wether it actually is\n",
    "camera_hidden = False\n",
    "\n",
    "# create a robot instance\n",
    "robot_instance = global_planning.Robot()\n",
    "\n",
    "# if unable to connect to the camera\n",
    "if not (cap.isOpened()):\n",
    "    print(\"Could not open video device\")\n",
    "else:\n",
    "    while(True):\n",
    "        # get the input frame by frame (shape (480,640,3))\n",
    "        ret, frame = cap.read() \n",
    "        cap.set(cv.CAP_PROP_FPS, CAMERA_FPS) \n",
    "        frame = cv.resize(frame, (IMAGE_WIDTH,IMAGE_HEIGHT), interpolation=cv.INTER_CUBIC) \n",
    "\n",
    "        # wait until keyboard input to initialize vision\n",
    "        if keyboard.is_pressed(KEYBOARD_INPUT):\n",
    "            init = True\n",
    "\n",
    "        # initialize \n",
    "        if init == True:\n",
    "\n",
    "            try:\n",
    "                # vision: start, obstacles and goal coordinates\n",
    "                original_coordinates, new_coordinates = vision.get_fop_coordinates(frame)\n",
    "                fop = vision.get_fop(frame, original_coordinates, new_coordinates)\n",
    "                start_x, start_y, alpha, width = vision.get_starting_position(fop)\n",
    "                obstacles = vision.get_obstacles(fop, width)\n",
    "                objective_x, objective_y = vision.get_objective(fop)\n",
    "\n",
    "                # global planning\n",
    "                converted_obstacles = [[tuple(arr) for arr in sublist] for sublist in obstacles]\n",
    "                converted_obstacles = global_planning.obstacle_dictionnary(converted_obstacles)\n",
    "                goal = (objective_x,objective_y)\n",
    "                robot_instance.update_coordinates(start_x, start_y, alpha,width)\n",
    "                obstacles_named = global_planning.naming_points(converted_obstacles,robot_instance,goal)\n",
    "                adg_list = global_planning.creating_adjacency_dictionnary(converted_obstacles,robot_instance,goal)\n",
    "                path = global_planning.finding_path(adg_list,obstacles_named)\n",
    "            \n",
    "                is_init = True\n",
    "            except Exception as e:\n",
    "                \n",
    "                print(\"Initialisation failed: \" + str(e))\n",
    "\n",
    "            init = False\n",
    "\n",
    "        if is_init:  \n",
    "        ################################## CALL FUNCTIONS HERE ################################## \n",
    "\n",
    "\n",
    "            fop = vision.get_fop(frame, original_coordinates, new_coordinates)\n",
    "            center_x, center_y, alpha, _ = vision.get_starting_position(fop)\n",
    "            robot_instance.update_coordinates(center_x,center_y,alpha,width)\n",
    "            vl, vr = Controlling_thymio.compute_wheel_speeds(robot_instance,(obstacles_named[path[1]][0],obstacles_named[path[1]][1]),robot_instance.robot_width,0.05,0.05,0.05,0.02)\n",
    "            Controlling_thymio.controlling_wheels_speed(int(vl),int(vr),aw,node)\n",
    "            \n",
    "            fop = cv.circle(fop, (center_x,center_y), radius=10, color=(0, 255, 0), thickness=-1)\n",
    "            cv.circle(fop, (objective_x, objective_y), radius=10, color=(255, 0, 0), thickness=-1)\n",
    "            cv.circle(fop, (start_x, start_y), radius=10, color=(0, 0, 255), thickness=-1)\n",
    "            for obstacle in obstacles:\n",
    "                for vertice in obstacle:\n",
    "                    cv.circle(fop, (vertice[0],vertice[1]), radius=10, color=(0, 255, 0), thickness=-1)\n",
    "            for i in range(len(path[:-1])):\n",
    "                cv.line(fop,(obstacles_named[path[i]][0],obstacles_named[path[i]][1]),(obstacles_named[path[i+1]][0],obstacles_named[path[i+1]][1]),(255,0,0),5)\n",
    "    \n",
    "\n",
    "        #########################################################################################\n",
    "        else:\n",
    "            # to output the raw feed\n",
    "            fop = frame\n",
    "\n",
    "        cv.imshow('Raw',frame)\n",
    "        cv.imshow('Processed',fop)\n",
    "\n",
    "        await client.sleep(0.001)\n",
    "        \n",
    "        # Close all windows and get out of the loop if ESC is pressed\n",
    "        if cv.waitKey(1) == 27:\n",
    "            cv.destroyAllWindows()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Node 0e83e7f0-32cd-4c48-b1de-4ae4fe01ea77"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tdmclient import ClientAsync, aw\n",
    "client = ClientAsync()\n",
    "import Controlling_thymio\n",
    "\n",
    "node = await client.wait_for_node()\n",
    "await node.lock()\n",
    "\n",
    "\n",
    "\n",
    "aw(node.lock())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Controlling_thymio.controlling_wheels_speed(50,50,aw,node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Controlling_thymio.controlling_wheels_speed(75,0,aw,node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Controlling_thymio.controlling_wheels_speed(0,0,aw,node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 1496, 2575, 1925, 0, 0]\n",
      "[0, 1929, 0, 2725, 3456, 0, 0]\n",
      "[0, 4870, 2032, 1785, 2802, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "await node.wait_for_variables({\"prox.horizontal\"})\n",
    "for i in range(10):\n",
    "    print(list(node.v.prox.horizontal))\n",
    "    await client.sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "False\n",
      "19\n",
      "True\n",
      "19\n",
      "True\n",
      "19\n",
      "True\n",
      "19\n",
      "True\n",
      "19\n",
      "True\n",
      "19\n",
      "True\n",
      "19\n",
      "True\n",
      "19\n",
      "True\n",
      "19\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "await node.wait_for_variables({\"acc\"})\n",
    "for i in range(10):\n",
    "    print(Controlling_thymio.kidnapping(node))\n",
    "    await client.sleep(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "aw(node.unlock())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MOBILEROBOTS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import keyboard\n",
    "import time\n",
    "\n",
    "import Controlling_thymio\n",
    "import global_planning\n",
    "import vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angle:[2.65711472]\n"
     ]
    }
   ],
   "source": [
    "# Vision example on an image\n",
    "\n",
    "# load the image\n",
    "img = cv.imread(\"testing_vision.jpg\")\n",
    "img = cv.resize(img, (640,480), interpolation=cv.INTER_CUBIC) \n",
    "\n",
    "# do the actual vision\n",
    "original_coordinates, new_coordinates = vision.get_fop_coordinates(img)\n",
    "fop = vision.get_fop(img, original_coordinates, new_coordinates)\n",
    "start_x, start_y, alpha, width = vision.get_starting_position(fop)\n",
    "obstacles = vision.get_obstacles(fop,width)\n",
    "objective_x, objective_y = vision.get_objective(fop)\n",
    "\n",
    "# draws everything and displays it\n",
    "output = fop.copy()\n",
    "cv.circle(output, (objective_x, objective_y), radius=10, color=(255, 0, 0), thickness=-1)\n",
    "cv.circle(output, (start_x, start_y), radius=10, color=(0, 0, 255), thickness=-1)\n",
    "for obstacle in obstacles:\n",
    "    for vertice in obstacle:\n",
    "        cv.circle(output, (vertice[0],vertice[1]), radius=10, color=(0, 255, 0), thickness=-1)\n",
    "\n",
    "print(\"Angle:\" + str(alpha))\n",
    "\n",
    "cv.imshow(\"image\", output)\n",
    "\n",
    "# press any key to close all windows\n",
    "cv.waitKey(0) \n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angle:[2.65711472]\n",
      "['R', 'P3', 'P5', 'G']\n"
     ]
    }
   ],
   "source": [
    "# Vision example on an image\n",
    "\n",
    "# load the image\n",
    "img = cv.imread(\"testing_vision.jpg\")\n",
    "img = cv.resize(img, (640,480), interpolation=cv.INTER_CUBIC) \n",
    "\n",
    "# do the actual vision\n",
    "original_coordinates, new_coordinates = vision.get_fop_coordinates(img)\n",
    "fop = vision.get_fop(img, original_coordinates, new_coordinates)\n",
    "start_x, start_y, alpha, width = vision.get_starting_position(fop)\n",
    "obstacles = vision.get_obstacles(fop,width)\n",
    "objective_x, objective_y = vision.get_objective(fop)\n",
    "\n",
    "# draws everything and displays it\n",
    "output = fop.copy()\n",
    "cv.circle(output, (objective_x, objective_y), radius=10, color=(255, 0, 0), thickness=-1)\n",
    "cv.circle(output, (start_x, start_y), radius=10, color=(0, 0, 255), thickness=-1)\n",
    "for obstacle in obstacles:\n",
    "    for vertice in obstacle:\n",
    "        cv.circle(output, (vertice[0],vertice[1]), radius=10, color=(0, 255, 0), thickness=-1)\n",
    "\n",
    "print(\"Angle:\" + str(alpha))\n",
    "\n",
    "converted_data = [[tuple(arr) for arr in sublist] for sublist in obstacles]\n",
    "print(converted_data)\n",
    "\n",
    "converted_data = global_planning.obstacle_dictionnary(converted_data)\n",
    "converted_data = global_planning.obstacle_dictionnary(converted_data)\n",
    "robot_instance = global_planning.Robot()\n",
    "goal = (objective_x,objective_y)\n",
    "\n",
    "robot_instance.update_coordinates(start_x, start_y, alpha,width)\n",
    "\n",
    "list_named2 = global_planning.naming_points(converted_data,robot_instance,goal)\n",
    "print(global_planning.Point_connection((372,140),(193,281),converted_data,robot_instance,goal))\n",
    "adg_list = global_planning.creating_adjacency_dictionnary(converted_data,robot_instance,goal)\n",
    "print(global_planning.finding_path(adg_list,list_named2))\n",
    "obstacles_named = global_planning.naming_points(converted_data,robot_instance,goal)\n",
    "adg_list = global_planning.creating_adjacency_list(converted_data,robot_instance,goal)\n",
    "path = global_planning.finding_path(adg_list,obstacles_named)\n",
    "print(path)\n",
    "for i in range(len(path[:-1])):\n",
    "    cv.line(output,(obstacles_named[path[i]][0],obstacles_named[path[i]][1]),(obstacles_named[path[i+1]][0],obstacles_named[path[i+1]][1]),(255,0,0),5)\n",
    "    \n",
    "\n",
    "cv.imshow(\"image\", output)\n",
    "\n",
    "# press any key to close all windows\n",
    "cv.waitKey(0) \n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the rectangular frame:\n",
      "580.0 369.0\n",
      "Starting coordinates and angle:\n",
      "(x ,y, alpha) = 533, 48, [2.65711472]\n",
      "Robot width:\n",
      "62\n",
      "Vertices of the obstacles:\n",
      "[[array([502, 134], dtype=int32), array([433, 312], dtype=int32), array([344, 269], dtype=int32), array([372, 140], dtype=int32)], [array([299, 138], dtype=int32), array([193, 281], dtype=int32), array([ 21, 141], dtype=int32), array([18, 92], dtype=int32)]]\n",
      "Goal coordinates:\n",
      "42 324\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensions of the rectangular frame:\")\n",
    "print(new_coordinates[3][0], new_coordinates[3][1])\n",
    "\n",
    "print(\"Starting coordinates and angle:\") # angle of the robot relative to the x axis, counterclockwise, expressed in radian in range (-pi, pi]\n",
    "print(\"(x ,y, alpha) = \" + str(start_x) + \", \"+ str(start_y) + \", \" + str(alpha))\n",
    "\n",
    "print(\"Robot width:\")\n",
    "print(width)\n",
    "\n",
    "print(\"Vertices of the obstacles:\")\n",
    "print(obstacles)\n",
    "\n",
    "print(\"Goal coordinates:\")\n",
    "print(objective_x, objective_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global constants here\n",
    "\n",
    "# width of the video feed\n",
    "IMAGE_WIDTH = 640\n",
    "# height of the video feed\n",
    "IMAGE_HEIGHT = 480\n",
    "# fps of the video feed\n",
    "CAMERA_FPS = 30\n",
    "# keyboard input to start\n",
    "KEYBOARD_INPUT = \"enter\"\n",
    "# number of frame thrown away to allow the camera to focus in the meantime\n",
    "CAMERA_REFRESH_TIME = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 is laptop webcam, 1 is USB camera (!COMPUTER DEPENDENT!)\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "init = False # boolean set to True on keyboard input to start initialisation\n",
    "is_init = False # boolean set to True once initialisation has succeeded\n",
    "black_frame_remaining = 0 # numbers of frames to throw away\n",
    "being_kidnapped = False # boolean set to True while the robot is being kidnapped\n",
    "\n",
    "# variable initialized at False irrelevant of wether it actually is\n",
    "camera_hidden = False\n",
    "\n",
    "# create a robot instance\n",
    "robot_instance = global_planning.Robot()\n",
    "\n",
    "# if unable to connect to the camera\n",
    "if not (cap.isOpened()):\n",
    "    print(\"Could not open video device\")\n",
    "else:\n",
    "    while(True):\n",
    "        # get the input frame by frame (shape (480,640,3))\n",
    "        ret, frame = cap.read() \n",
    "        cap.set(cv.CAP_PROP_FPS, CAMERA_FPS) \n",
    "        frame = cv.resize(frame, (IMAGE_WIDTH,IMAGE_HEIGHT), interpolation=cv.INTER_CUBIC) \n",
    "\n",
    "        # wait until keyboard input to initialize vision\n",
    "        if keyboard.is_pressed(KEYBOARD_INPUT):\n",
    "            init = True\n",
    "\n",
    "        # reinitialize the robot after a kidnapping\n",
    "        if being_kidnapped: \n",
    "            if not Controlling_thymio.kidnapping(node):\n",
    "                \n",
    "                # to give time to the kidnapper to get out of the frame\n",
    "                time.sleep(1)\n",
    "\n",
    "                # reinitialize the starting position of the robot\n",
    "                fop = vision.get_fop(frame, original_coordinates, new_coordinates)\n",
    "                start_x, start_y, alpha, width = vision.get_starting_position(fop)\n",
    "\n",
    "                # reinitialize the global planning\n",
    "                converted_obstacles = [[tuple(arr) for arr in sublist] for sublist in obstacles]\n",
    "                converted_obstacles = global_planning.create_dictionnary(converted_obstacles)\n",
    "                goal = (objective_x, objective_y)\n",
    "                robot_instance.update_coordinates(start_x, start_y, alpha, width)\n",
    "                obstacles_named = global_planning.naming_points(converted_data, robot_instance, goal)\n",
    "                adg_list = global_planning.creating_adjacency_list(converted_data, robot_instance, goal)\n",
    "                path = global_planning.finding_path(adg_list, obstacles_named)\n",
    "\n",
    "                is_init = True\n",
    "                being_kidnapped = False\n",
    "        \n",
    "        # initialize \n",
    "        if init == True:\n",
    "\n",
    "            try:\n",
    "                # vision: start, obstacles and goal coordinates\n",
    "                original_coordinates, new_coordinates = vision.get_fop_coordinates(frame)\n",
    "                fop = vision.get_fop(frame, original_coordinates, new_coordinates)\n",
    "                start_x, start_y, alpha, width = vision.get_starting_position(fop)\n",
    "                obstacles = vision.get_obstacles(fop, width)\n",
    "                objective_x, objective_y = vision.get_objective(fop)\n",
    "\n",
    "                # global planning\n",
    "                converted_obstacles = [[tuple(arr) for arr in sublist] for sublist in obstacles]\n",
    "                converted_obstacles = global_planning.create_dictionnary(converted_obstacles)\n",
    "                goal = (objective_x,objective_y)\n",
    "                robot_instance.update_coordinates(start_x, start_y, alpha,width)\n",
    "                obstacles_named = global_planning.naming_points(converted_data,robot_instance,goal)\n",
    "                adg_list = global_planning.creating_adjacency_list(converted_data,robot_instance,goal)\n",
    "                path = global_planning.finding_path(adg_list,obstacles_named)\n",
    "\n",
    "                is_init = True\n",
    "            except:\n",
    "                print(\"Initialisation failed\")\n",
    "\n",
    "            init = False\n",
    "\n",
    "        if is_init:  \n",
    "        ################################## CALL FUNCTIONS HERE ################################## \n",
    "            \n",
    "            # get out of the loop if the robot is being kidnapped\n",
    "            if Controlling_thymio.kidnapping(node):\n",
    "                being_kidnapped = True\n",
    "                is_init = False\n",
    "                continue\n",
    "\n",
    "            fop = vision.get_fop(frame, original_coordinates, new_coordinates)\n",
    "            center_x, center_y = vision.get_robot_center(fop)\n",
    "            \n",
    "            # camera was covered, now uncovered\n",
    "            if center_x != 0 and center_y != 0 and camera_hidden:\n",
    "                camera_hidden = False\n",
    "                black_frame_remaining = CAMERA_REFRESH_TIME # to give it time to gain focus\n",
    "\n",
    "            # camera was uncovered, now covered -> navigation using Kalman filter\n",
    "            elif center_x == 0 and center_y == 0:\n",
    "                camera_hidden = True\n",
    "\n",
    "                # DO KALMAN NAVIGATION HERE\n",
    "\n",
    "            # camera uncovered and usable -> navigation using vision\n",
    "            elif black_frame_remaining <= 0:\n",
    "                fop = cv.circle(fop, (center_x,center_y), radius=10, color=(0, 255, 0), thickness=-1)\n",
    "\n",
    "                # DO VISION NAVIGATION HERE\n",
    "                \n",
    "            else:\n",
    "                # set the first frames after uncovering to black to allow time to focus\n",
    "                fop = cv.cvtColor(fop, cv.COLOR_BGR2GRAY)\n",
    "                _, fop = cv.threshold(fop,255,255,cv.THRESH_BINARY)\n",
    "                black_frame_remaining -= 1\n",
    "\n",
    "\n",
    "            # draw everything\n",
    "            if not camera_hidden and black_frame_remaining <= 0:\n",
    "                cv.circle(fop, (objective_x, objective_y), radius=10, color=(255, 0, 0), thickness=-1)\n",
    "                cv.circle(fop, (start_x, start_y), radius=10, color=(0, 0, 255), thickness=-1)\n",
    "                for obstacle in obstacles:\n",
    "                    for vertice in obstacle:\n",
    "                        cv.circle(fop, (vertice[0],vertice[1]), radius=10, color=(0, 255, 0), thickness=-1)\n",
    "                for i in range(len(path[:-1])):\n",
    "                    cv.line(output,(obstacles_named[path[i]][0],obstacles_named[path[i]][1]),(obstacles_named[path[i+1]][0],obstacles_named[path[i+1]][1]),(255,0,0),5)\n",
    "    \n",
    "\n",
    "        #########################################################################################\n",
    "        else:\n",
    "            # to output the raw feed\n",
    "            fop = frame\n",
    "\n",
    "        cv.imshow('preview',fop)\n",
    "        \n",
    "        # Close all windows and get out of the loop if ESC is pressed\n",
    "        if cv.waitKey(1) == 27:\n",
    "            cv.destroyAllWindows()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Node 0e83e7f0-32cd-4c48-b1de-4ae4fe01ea77"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tdmclient import ClientAsync, aw\n",
    "client = ClientAsync()\n",
    "import Controlling_thymio\n",
    "\n",
    "node = await client.wait_for_node()\n",
    "await node.lock()\n",
    "\n",
    "\n",
    "\n",
    "aw(node.lock())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Controlling_thymio.controlling_wheels_speed(50,50,aw,node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Controlling_thymio.controlling_wheels_speed(75,0,aw,node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Controlling_thymio.controlling_wheels_speed(0,0,aw,node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 1496, 2575, 1925, 0, 0]\n",
      "[0, 1929, 0, 2725, 3456, 0, 0]\n",
      "[0, 4870, 2032, 1785, 2802, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "await node.wait_for_variables({\"prox.horizontal\"})\n",
    "for i in range(10):\n",
    "    print(list(node.v.prox.horizontal))\n",
    "    await client.sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "await node.wait_for_variables({\"acc\"})\n",
    "for i in range(10):\n",
    "    print(Controlling_thymio.kidnapping(node))\n",
    "    await client.sleep(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "aw(node.unlock())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MOBILEROBOTS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

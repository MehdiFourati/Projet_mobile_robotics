{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import keyboard\n",
    "import time\n",
    "\n",
    "import Controlling_thymio\n",
    "import global_planning\n",
    "import vision\n",
    "import loc_avoid\n",
    "from ekf import ExtendedKalmanFilter\n",
    "from ekf import apply_kalman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global constants here\n",
    "\n",
    "IMAGE_WIDTH = 640 # width of the video feed\n",
    "\n",
    "IMAGE_HEIGHT = 480 # height of the video feed\n",
    "\n",
    "CAMERA_FPS = 30 # fps of the video feed\n",
    "\n",
    "KEYBOARD_INPUT = \"enter\" # keyboard input to start\n",
    "\n",
    "CAMERA_REFRESH_TIME = 30 # number of frame thrown away to allow the camera to focus in the meantime\n",
    "\n",
    "KP_LINEAR = 5 # linear proportional gain in PI controller\n",
    "\n",
    "KI_LINEAR = 0.5 # linear integral gain in PI controller\n",
    "\n",
    "KP_ANGULAR = 15 # angular proportional gain in PI controller\n",
    "\n",
    "KI_ANGULAR = 1.5 # angular linear gain in PI controller\n",
    "\n",
    "PATH_DELTA = 7 # acccepted difference in pixels between the actual robot's position and its goal\n",
    "\n",
    "ANGULAR_DELTA = 0.15 # accepted difference in radian between the actual robot's angle and its goal\n",
    "\n",
    "TURNING_SPEED = 100 # speed of the wheel when turning\n",
    "\n",
    "STRAIGHT_SPEED = 150 # speed of the wheel when going straight\n",
    "\n",
    "MAX_STRAIGHT_SPEED = 200 # maximum speed to be sent to the robot\n",
    "\n",
    "SKIPPED_FRAME = 3 # get one frame every X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdmclient import ClientAsync, aw\n",
    "client = ClientAsync()\n",
    "import Controlling_thymio\n",
    "\n",
    "node = await client.wait_for_node()\n",
    "\n",
    "await node.lock()\n",
    "aw(node.lock())\n",
    "\n",
    "await node.wait_for_variables({\"acc\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R', 'P1', 'G']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehdi\\AppData\\Local\\Temp\\ipykernel_23812\\4003581336.py:143: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  Controlling_thymio.set_speed(int(left_wheel_speed),int(right_wheel_speed),aw,node)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (5,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 192\u001b[0m\n\u001b[0;32m    189\u001b[0m speed \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mint\u001b[39m(left_wheel_speed),\u001b[38;5;28mint\u001b[39m(right_wheel_speed)]\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m#x0 = [position[0], position[1], position[2], speed[0], speed[1]]\u001b[39;00m\n\u001b[1;32m--> 192\u001b[0m x,_ \u001b[38;5;241m=\u001b[39m apply_kalman(ekf,\u001b[38;5;129;01mnot\u001b[39;00m camera_hidden,position,speed)\n\u001b[0;32m    193\u001b[0m new_position \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m3\u001b[39m]\n\u001b[0;32m    194\u001b[0m robot_instance\u001b[38;5;241m.\u001b[39mupdate_coordinates(new_position[\u001b[38;5;241m0\u001b[39m], new_position[\u001b[38;5;241m1\u001b[39m], new_position[\u001b[38;5;241m2\u001b[39m], width)\n",
      "File \u001b[1;32mc:\\Users\\mehdi\\Documents\\GitHub\\Projet_mobile_robotics\\ekf.py:137\u001b[0m, in \u001b[0;36mapply_kalman\u001b[1;34m(kalman, camera_on, position, speed, dt)\u001b[0m\n\u001b[0;32m    135\u001b[0m     kalman\u001b[38;5;241m.\u001b[39mset_time_t(time\u001b[38;5;241m.\u001b[39mtime())\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m camera_on:\n\u001b[1;32m--> 137\u001b[0m     z \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([position[\u001b[38;5;241m0\u001b[39m],position[\u001b[38;5;241m1\u001b[39m],position[\u001b[38;5;241m2\u001b[39m],speed[\u001b[38;5;241m0\u001b[39m],speed[\u001b[38;5;241m1\u001b[39m]])\n\u001b[0;32m    138\u001b[0m     z\u001b[38;5;241m=\u001b[39mz\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (5,) + inhomogeneous part."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# 0 is laptop webcam, 1 is USB camera (!COMPUTER DEPENDENT!)\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "init = False # boolean set to True on keyboard input to start initialisation\n",
    "is_init = False # boolean set to True once initialisation has succeeded\n",
    "black_frame_remaining = 0 # numbers of frames to throw away\n",
    "being_kidnapped = False # boolean set to True while the robot is being kidnapped\n",
    "error_linear = [] # array of all linear errors\n",
    "error_angle = [] # array of all angular errors\n",
    "initial_turn = True # boolean set to True while the first orientation is not done\n",
    "frame_number = 0 # to get one frame every X\n",
    "\n",
    "\n",
    "# variable initialized at False irrelevant of wether it actually is\n",
    "camera_hidden = False\n",
    "\n",
    "# create a robot instance\n",
    "robot_instance = global_planning.Robot()\n",
    "\n",
    "# if unable to connect to the camera\n",
    "if not (cap.isOpened()):\n",
    "    print(\"Could not open video device\")\n",
    "else:\n",
    "    while(True):\n",
    "        # get the input frame by frame (shape (480,640,3))\n",
    "        ret, frame = cap.read() \n",
    "        cap.set(cv.CAP_PROP_FPS, CAMERA_FPS) \n",
    "        frame = cv.resize(frame, (IMAGE_WIDTH,IMAGE_HEIGHT), interpolation=cv.INTER_CUBIC) \n",
    "\n",
    "        # wait until keyboard input to initialize vision\n",
    "        if keyboard.is_pressed(KEYBOARD_INPUT):\n",
    "            init = True\n",
    "\n",
    "        # reinitialize the robot after a kidnapping\n",
    "        if being_kidnapped: \n",
    "            if not Controlling_thymio.kidnapping(node):\n",
    "                \n",
    "                # to give time to the kidnapper to get out of the frame\n",
    "                time.sleep(3)\n",
    "\n",
    "                # reinitialize the starting position of the robot\n",
    "                fop = vision.get_fop(frame, original_coordinates, new_coordinates)\n",
    "                start_x, start_y, robot_angle, width = vision.get_robot_position(fop)\n",
    "\n",
    "                # reinitialize the global planning\n",
    "                converted_obstacles = [[tuple(arr) for arr in sublist] for sublist in obstacles]\n",
    "                converted_obstacles = global_planning.obstacle_dictionnary(converted_obstacles)\n",
    "                goal = (objective_x, objective_y)\n",
    "                robot_instance.update_coordinates(start_x, start_y, robot_angle, width)\n",
    "                obstacles_named = global_planning.naming_points(converted_obstacles, robot_instance, goal)\n",
    "                adg_list = global_planning.creating_adjacency_dictionnary(converted_obstacles, robot_instance, goal)\n",
    "                path = global_planning.finding_path(adg_list, obstacles_named)\n",
    "\n",
    "                black_frame_remaining = 0\n",
    "                camera_hidden = False\n",
    "                initial_turn = True\n",
    "                is_init = True\n",
    "                being_kidnapped = False\n",
    "        \n",
    "        # initialize \n",
    "        if init == True:\n",
    "\n",
    "            try:\n",
    "                # vision: start, obstacles and goal coordinates\n",
    "                original_coordinates, new_coordinates = vision.get_fop_coordinates(frame)\n",
    "                fop = vision.get_fop(frame, original_coordinates, new_coordinates)\n",
    "                start_x, start_y, robot_angle, width = vision.get_robot_position(fop)\n",
    "                obstacles = vision.get_obstacles(fop, width)\n",
    "                objective_x, objective_y = vision.get_objective(fop)\n",
    "\n",
    "                # global planning\n",
    "                converted_obstacles = [[tuple(arr) for arr in sublist] for sublist in obstacles]\n",
    "                converted_obstacles = global_planning.obstacle_dictionnary(converted_obstacles)\n",
    "                goal = (objective_x,objective_y)\n",
    "                robot_instance.update_coordinates(start_x, start_y, robot_angle,width)\n",
    "                obstacles_named = global_planning.naming_points(converted_obstacles,robot_instance,goal)\n",
    "                adg_list = global_planning.creating_adjacency_dictionnary(converted_obstacles,robot_instance,goal)\n",
    "                path = global_planning.finding_path(adg_list,obstacles_named)\n",
    "                print(path)\n",
    "                black_frame_remaining = 0\n",
    "                camera_hidden = False\n",
    "                being_kidnapped = False\n",
    "                is_init = True\n",
    "            except Exception as e:\n",
    "                print(\"Initialisation failed: \" + str(e))\n",
    "\n",
    "            init = False\n",
    "\n",
    "        if is_init:  \n",
    "        ################################## MOTION CONTROL HERE ################################## \n",
    "            \n",
    "            # get out of the loop if the robot is being kidnapped\n",
    "            if Controlling_thymio.kidnapping(node):\n",
    "                being_kidnapped = True\n",
    "                is_init = False\n",
    "                continue\n",
    "\n",
    "            fop = vision.get_fop(frame, original_coordinates, new_coordinates)\n",
    "\n",
    "            # to use one frame every X\n",
    "            if i%SKIPPED_FRAME == 0:\n",
    "\n",
    "                try:\n",
    "                    center_x, center_y, robot_angle, width = vision.get_robot_position(fop)\n",
    "                except:\n",
    "                    center_x = 0\n",
    "                    center_y = 0\n",
    "                    robot_angle = 0\n",
    "\n",
    "            frame_number += 1\n",
    "            \n",
    "            # camera was covered, now uncovered\n",
    "            if center_x != 0 and center_y != 0 and camera_hidden:\n",
    "                camera_hidden = False\n",
    "                black_frame_remaining = CAMERA_REFRESH_TIME # to give it time to gain focus\n",
    "\n",
    "            # camera was uncovered, now covered\n",
    "            elif center_x == 0 and center_y == 0:\n",
    "                camera_hidden = True\n",
    "\n",
    "                loc_avoid.local_avoidance(node,robot_instance,aw)\n",
    "                # KALMAN HERE\n",
    "                ekf = ExtendedKalmanFilter([center_x,center_y,robot_angle,0,0])\n",
    "                ekf.set_time_t(time.time())\n",
    "\n",
    "            # camera uncovered and usable -> navigation using vision\n",
    "            elif black_frame_remaining <= 0:\n",
    "                fop = cv.circle(fop, (center_x,center_y), radius=10, color=(0, 255, 0), thickness=-1)\n",
    "\n",
    "                # ADD PROXIMITY AVOIDANCE\n",
    "                loc_avoid.local_avoidance(node,robot_instance,aw)\n",
    "\n",
    "                start_point = np.array([obstacles_named[path[0]][0],obstacles_named[path[0]][1]])\n",
    "                end_point = np.array([obstacles_named[path[1]][0],obstacles_named[path[1]][1]])\n",
    "                \n",
    "                # traget point after the actual end point\n",
    "                try:\n",
    "                    next_point = np.array([obstacles_named[path[2]][0],obstacles_named[path[2]][1]])\n",
    "                except:\n",
    "                    next_point = [0, 0]\n",
    "\n",
    "                robot_center = np.array([center_x, center_y])\n",
    "\n",
    "                # do the initial orientation\n",
    "                if initial_turn:\n",
    "                    \n",
    "                    # turning\n",
    "                    error_angle = Controlling_thymio.get_angular_error(end_point, next_point, robot_angle)\n",
    "                    left_wheel_speed = -1 * np.sign(error_angle) * TURNING_SPEED\n",
    "                    right_wheel_speed = np.sign(error_angle) * TURNING_SPEED\n",
    "                    Controlling_thymio.set_speed(int(left_wheel_speed),int(right_wheel_speed),aw,node)\n",
    "                    \n",
    "                    # first turn is done\n",
    "                    if Controlling_thymio.get_angular_error(end_point, next_point, robot_angle) < ANGULAR_DELTA:\n",
    "                        initial_turn = False\n",
    "                        Controlling_thymio.set_speed(0,0,aw,node)\n",
    "\n",
    "                # check if the next point as been reached\n",
    "                if Controlling_thymio.reached_linear_target(end_point, robot_center, PATH_DELTA):\n",
    "                    \n",
    "                    # if the last point has been reached\n",
    "                    if next_point[0] == 0 and next_point[1] == 0:\n",
    "                        print(\"Target reached\")\n",
    "                        Controlling_thymio.set_speed(0,0,aw,node)\n",
    "                        time.sleep(10)\n",
    "                    else:\n",
    "                        if Controlling_thymio.get_angular_error(end_point, next_point, robot_angle) < ANGULAR_DELTA:\n",
    "                            # finished turning, ready to go straight\n",
    "                            path = path[1:]\n",
    "\n",
    "                        else:\n",
    "                            # turning\n",
    "                            error_angle = Controlling_thymio.get_angular_error(end_point, next_point, robot_angle)\n",
    "                            left_wheel_speed = -1 * np.sign(error_angle) * TURNING_SPEED\n",
    "                            right_wheel_speed = np.sign(error_angle) * TURNING_SPEED\n",
    "                            Controlling_thymio.set_speed(int(left_wheel_speed),int(right_wheel_speed),aw,node)\n",
    "                else:\n",
    "                    # does not do the straight control if doing the initial turning\n",
    "                    if not initial_turn:\n",
    "                        # going straight\n",
    "                        error_linear = np.append(error_linear, Controlling_thymio.get_linear_error(start_point, end_point,robot_center))\n",
    "                        error_angle = np.append(error_angle, Controlling_thymio.get_angular_error(start_point, end_point, robot_angle))\n",
    "                        \n",
    "                        left_wheel_speed = STRAIGHT_SPEED - Controlling_thymio.PI_controller(error_angle, KP_ANGULAR, KI_ANGULAR) + Controlling_thymio.PI_controller(error_linear, KP_LINEAR, KI_LINEAR)\n",
    "                        right_wheel_speed = STRAIGHT_SPEED + Controlling_thymio.PI_controller(error_angle, KP_ANGULAR, KI_ANGULAR) - Controlling_thymio.PI_controller(error_linear, KP_LINEAR, KI_LINEAR)\n",
    "                        \n",
    "                        # limit the maximum speed of the wheels\n",
    "                        if left_wheel_speed > MAX_STRAIGHT_SPEED: left_wheel_speed = MAX_STRAIGHT_SPEED\n",
    "                        if right_wheel_speed > MAX_STRAIGHT_SPEED: right_wheel_speed = MAX_STRAIGHT_SPEED\n",
    "                        if left_wheel_speed < -MAX_STRAIGHT_SPEED: left_wheel_speed = -MAX_STRAIGHT_SPEED\n",
    "                        if right_wheel_speed < -MAX_STRAIGHT_SPEED: right_wheel_speed = -MAX_STRAIGHT_SPEED\n",
    "                        \n",
    "                        Controlling_thymio.set_speed(int(left_wheel_speed),int(right_wheel_speed),aw,node)\n",
    "                    else:\n",
    "                        pass\n",
    "            else:\n",
    "                # set the first frames after uncovering to black to allow time to focus -> navigation using extended Kalman filter\n",
    "                fop = cv.cvtColor(fop, cv.COLOR_BGR2GRAY)\n",
    "                _, fop = cv.threshold(fop,255,255,cv.THRESH_BINARY)\n",
    "                black_frame_remaining -= 1\n",
    "\n",
    "                # DO KALMAN NAVIGATION HERE\n",
    "                position = [center_x, center_y, robot_angle]\n",
    "                speed = [int(left_wheel_speed),int(right_wheel_speed)]\n",
    "                #x0 = [position[0], position[1], position[2], speed[0], speed[1]]\n",
    "                \n",
    "                x,_ = apply_kalman(ekf,not camera_hidden,position,speed)\n",
    "                new_position = x[0:3]\n",
    "                robot_instance.update_coordinates(new_position[0], new_position[1], new_position[2], width)\n",
    "                print(robot_instance.center_x,robot_instance.center_y)\n",
    "\n",
    "                # ADD PROXIMITY AVOIDANCE\n",
    "                loc_avoid.local_avoidance(node,robot_instance,aw)\n",
    "\n",
    "            # draw everything\n",
    "            #if not camera_hidden and black_frame_remaining <= 0:\n",
    "            cv.circle(fop, (objective_x, objective_y), radius=10, color=(255, 0, 0), thickness=-1)\n",
    "            cv.circle(fop, (start_x, start_y), radius=10, color=(0, 0, 255), thickness=-1)\n",
    "            for obstacle in obstacles:\n",
    "                for vertice in obstacle:\n",
    "                    cv.circle(fop, (vertice[0],vertice[1]), radius=10, color=(0, 255, 0), thickness=-1)\n",
    "            for i in range(len(path[:-1])):\n",
    "                cv.line(fop,(obstacles_named[path[i]][0],obstacles_named[path[i]][1]),(obstacles_named[path[i+1]][0],obstacles_named[path[i+1]][1]),(255,0,0),5)\n",
    "    \n",
    "\n",
    "        #########################################################################################\n",
    "        else:\n",
    "            # to output the raw feed\n",
    "            fop = frame\n",
    "\n",
    "        cv.imshow('Raw',frame)\n",
    "        cv.imshow('Processed',fop)\n",
    "\n",
    "        await client.sleep(0.001)\n",
    "        \n",
    "        # Close all windows and get out of the loop if ESC is pressed\n",
    "        if cv.waitKey(1) == 27:\n",
    "            cv.destroyAllWindows()\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MOBILEROBOTS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

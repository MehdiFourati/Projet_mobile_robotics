{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import keyboard\n",
    "import time\n",
    "\n",
    "import Controlling_thymio\n",
    "import global_planning\n",
    "import vision\n",
    "import loc_avoid\n",
    "from ekf import ExtendedKalmanFilter\n",
    "from ekf import apply_kalman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global constants here\n",
    "\n",
    "IMAGE_WIDTH = 640 # width of the video feed\n",
    "\n",
    "IMAGE_HEIGHT = 480 # height of the video feed\n",
    "\n",
    "CAMERA_FPS = 30 # fps of the video feed\n",
    "\n",
    "KEYBOARD_INPUT = \"enter\" # keyboard input to start\n",
    "\n",
    "CAMERA_REFRESH_TIME = 30 # number of frame thrown away to allow the camera to focus in the meantime\n",
    "\n",
    "SKIPPED_FRAME = 3 # get one frame every X\n",
    "\n",
    "GO_STRAIGHT = 10 # numbers of frame to go straight after avoiding an obstacle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdmclient import ClientAsync, aw\n",
    "client = ClientAsync()\n",
    "import Controlling_thymio\n",
    "\n",
    "node = await client.wait_for_node()\n",
    "\n",
    "await node.lock()\n",
    "aw(node.lock())\n",
    "\n",
    "await node.wait_for_variables({\"acc\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_angle(angle):\n",
    "    if  isinstance(angle, np.ndarray):\n",
    "        return float(angle[0])\n",
    "    else:\n",
    "        return float(angle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 is laptop webcam, 1 is USB camera (!COMPUTER DEPENDENT!)\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "init = False # boolean set to True on keyboard input to start initialisation\n",
    "is_init = False # boolean set to True once initialisation has succeeded\n",
    "black_frame_remaining = 0 # numbers of frames to throw away\n",
    "being_kidnapped = False # boolean set to True while the robot is being kidnapped\n",
    "error_linear = [] # array of all linear errors\n",
    "error_angle = [] # array of all angular errors\n",
    "initial_turn = True # boolean set to True while the first orientation is not done\n",
    "frame_number = 0 # to get one frame every X\n",
    "frame_straight = 0\n",
    "\n",
    "# variable initialized at False irrelevant of wether it actually is\n",
    "robot_not_found = False # boolean set to True if robot not found for one frame\n",
    "camera_hidden = False # boolean set to True if robot not found for multiple frames\n",
    "\n",
    "# create a robot instance\n",
    "robot_instance = global_planning.Robot()\n",
    "\n",
    "# if unable to connect to the camera\n",
    "if not (cap.isOpened()):\n",
    "    print(\"Could not open video device\")\n",
    "else:\n",
    "    while(True):\n",
    "        # get the input frame by frame (shape (480,640,3))\n",
    "        ret, frame = cap.read() \n",
    "        cap.set(cv.CAP_PROP_FPS, CAMERA_FPS) \n",
    "        frame = cv.resize(frame, (IMAGE_WIDTH,IMAGE_HEIGHT), interpolation=cv.INTER_CUBIC) \n",
    "\n",
    "        # wait until keyboard input to initialize vision\n",
    "        if keyboard.is_pressed(KEYBOARD_INPUT):\n",
    "            init = True\n",
    "\n",
    "        # reinitialize the robot after a kidnapping\n",
    "        if being_kidnapped: \n",
    "            if not Controlling_thymio.kidnapping(node):\n",
    "                \n",
    "                # to give time to the kidnapper to get out of the frame\n",
    "                time.sleep(3)\n",
    "                \n",
    "                # reinitialize the starting position of the robot\n",
    "                fop = vision.get_fop(frame, original_coordinates, new_coordinates)\n",
    "                try:\n",
    "                    start_x, start_y, robot_angle, width = vision.get_robot_position(fop)\n",
    "                except:\n",
    "                    break\n",
    "\n",
    "                # reinitialize the global planning\n",
    "                converted_obstacles = [[tuple(arr) for arr in sublist] for sublist in obstacles]\n",
    "                converted_obstacles = global_planning.obstacle_dictionnary(converted_obstacles)\n",
    "                goal = (objective_x, objective_y)\n",
    "                robot_instance.update_coordinates(start_x, start_y, robot_angle, width)\n",
    "                obstacles_named = global_planning.naming_points(converted_obstacles, robot_instance, goal)\n",
    "                adg_list = global_planning.creating_adjacency_dictionnary(converted_obstacles, robot_instance, goal)\n",
    "                path = global_planning.finding_path(adg_list, obstacles_named)\n",
    "\n",
    "                black_frame_remaining = 0\n",
    "                camera_hidden = False\n",
    "                initial_turn = True\n",
    "                is_init = True\n",
    "                being_kidnapped = False\n",
    "        \n",
    "        # initialize \n",
    "        if init == True:\n",
    "\n",
    "            try:\n",
    "                # vision: start, obstacles and goal coordinates\n",
    "                original_coordinates, new_coordinates = vision.get_fop_coordinates(frame)\n",
    "                fop = vision.get_fop(frame, original_coordinates, new_coordinates)\n",
    "                start_x, start_y, robot_angle, width = vision.get_robot_position(fop)\n",
    "                obstacles = vision.get_obstacles(fop, width)\n",
    "                objective_x, objective_y = vision.get_objective(fop)\n",
    "\n",
    "                # global planning\n",
    "                converted_obstacles = [[tuple(arr) for arr in sublist] for sublist in obstacles]\n",
    "                converted_obstacles = global_planning.obstacle_dictionnary(converted_obstacles)\n",
    "                goal = (objective_x,objective_y)\n",
    "                robot_instance.update_coordinates(start_x, start_y, robot_angle,width)\n",
    "                obstacles_named = global_planning.naming_points(converted_obstacles,robot_instance,goal)\n",
    "                adg_list = global_planning.creating_adjacency_dictionnary(converted_obstacles,robot_instance,goal)\n",
    "                path = global_planning.finding_path(adg_list,obstacles_named)\n",
    "                \n",
    "                # extended kalman filter\n",
    "                ekf = ExtendedKalmanFilter(([start_x,start_y,robot_angle,0,0]))\n",
    "                ekf.set_time_t(time.time())\n",
    "                left_wheel_speed = 0\n",
    "                right_wheel_speed = 0\n",
    "\n",
    "                black_frame_remaining = 0\n",
    "                camera_hidden = False\n",
    "                being_kidnapped = False\n",
    "                is_init = True\n",
    "            except Exception as e:\n",
    "                print(\"Initialisation failed: \" + str(e))\n",
    "\n",
    "            init = False\n",
    "\n",
    "        if is_init:  \n",
    "        ################################## MOTION CONTROL HERE ################################## \n",
    "            \n",
    "            # get out of the loop if the robot is being kidnapped\n",
    "            if Controlling_thymio.kidnapping(node):\n",
    "                being_kidnapped = True\n",
    "                is_init = False\n",
    "                continue\n",
    "\n",
    "            fop = vision.get_fop(frame, original_coordinates, new_coordinates)\n",
    "\n",
    "            # to use one frame every X\n",
    "            if frame_number%SKIPPED_FRAME == 0:\n",
    "\n",
    "                try:\n",
    "                    center_x, center_y, robot_angle, width = vision.get_robot_position(fop)\n",
    "                    robot_instance.update_coordinates(center_x, center_y, robot_angle, width)\n",
    "                    robot_not_found = False\n",
    "                except:\n",
    "                    center_x = 0\n",
    "                    center_y = 0\n",
    "                    robot_angle = float(0)\n",
    "                    if robot_not_found:\n",
    "                        camera_hidden = True\n",
    "                    robot_not_found = True\n",
    "\n",
    "            frame_number += 1\n",
    "            \n",
    "            # ekf update\n",
    "            position = [center_x, center_y, check_angle(robot_angle)]\n",
    "            speed = [float(left_wheel_speed),float(right_wheel_speed)]\n",
    "            \n",
    "            try:\n",
    "                x, _ = apply_kalman(ekf, not camera_hidden, position, speed)\n",
    "                new_position = x[0:3]  # Extract the filtered position\n",
    "                \n",
    "            except ValueError as e:\n",
    "                print(f\"Error during Kalman filter update: {e}\")\n",
    "                new_position = [center_x, center_y, robot_angle]\n",
    "\n",
    "            # camera was covered, now uncovered\n",
    "            if center_x != 0 and center_y != 0 and camera_hidden:\n",
    "                camera_hidden = False\n",
    "                black_frame_remaining = CAMERA_REFRESH_TIME # to give it time to gain focus\n",
    "\n",
    "                # position updated using Kalman\n",
    "                robot_instance.update_coordinates(new_position[0], new_position[1], new_position[2], width)\n",
    "\n",
    "            # camera was uncovered, now covered\n",
    "            elif center_x == 0 and center_y == 0:\n",
    "                # position updated using Kalman\n",
    "                robot_instance.update_coordinates(new_position[0], new_position[1], new_position[2], width)\n",
    "            \n",
    "            # camera was recently uncovered, set some frames to black to allow it time to gain focus\n",
    "            elif black_frame_remaining > 0:\n",
    "                # set the first frames after uncovering to black to allow time to focus -> navigation using extended Kalman filter\n",
    "                fop = cv.cvtColor(fop, cv.COLOR_BGR2GRAY)\n",
    "                _, fop = cv.threshold(fop,255,255,cv.THRESH_BINARY)\n",
    "                black_frame_remaining -= 1\n",
    "\n",
    "                # position updated using Kalman\n",
    "                robot_instance.update_coordinates(new_position[0], new_position[1], new_position[2], width)\n",
    "            \n",
    "            start_point = np.array([obstacles_named[path[0]][0],obstacles_named[path[0]][1]])\n",
    "            end_point = np.array([obstacles_named[path[1]][0],obstacles_named[path[1]][1]])\n",
    "            \n",
    "            # traget point after the actual end point\n",
    "            try:\n",
    "                next_point = np.array([obstacles_named[path[2]][0],obstacles_named[path[2]][1]])\n",
    "            except:\n",
    "                next_point = [0, 0]\n",
    "\n",
    "            # proximity avoidance\n",
    "            if loc_avoid.check_local_nav(node, robot_instance, aw):\n",
    "                left_wheel_speed, right_wheel_speed = loc_avoid.local_avoidance(node, robot_instance, aw)\n",
    "                initial_turn = True\n",
    "                frame_straight = GO_STRAIGHT \n",
    "            # update of the wheel speed\n",
    "            else:\n",
    "                if frame_straight <= 0:\n",
    "                    left_wheel_speed, right_wheel_speed, error_linear, error_angle, initial_turn, path = Controlling_thymio.compute_wheel_speed(initial_turn, start_point, end_point, next_point, error_linear, error_angle, robot_instance, path, aw, node)   \n",
    "                frame_straight -= 1\n",
    "\n",
    "            robot_instance.update_speed(left_wheel_speed, right_wheel_speed)\n",
    "\n",
    "            # draw everything\n",
    "            #if not camera_hidden and black_frame_remaining <= 0:\n",
    "            cv.circle(fop, (robot_instance.center_x,robot_instance.center_y), radius=10, color=(0, 255, 0), thickness=-1)\n",
    "            cv.circle(fop, (objective_x, objective_y), radius=10, color=(255, 0, 0), thickness=-1)\n",
    "            cv.circle(fop, (start_x, start_y), radius=10, color=(0, 0, 255), thickness=-1)\n",
    "            for obstacle in obstacles:\n",
    "                for vertice in obstacle:\n",
    "                    cv.circle(fop, (vertice[0],vertice[1]), radius=10, color=(0, 255, 0), thickness=-1)\n",
    "            for i in range(len(path[:-1])):\n",
    "                cv.line(fop,(obstacles_named[path[i]][0],obstacles_named[path[i]][1]),(obstacles_named[path[i+1]][0],obstacles_named[path[i+1]][1]),(255,0,0),5)\n",
    "    \n",
    "        #########################################################################################\n",
    "        else:\n",
    "            # to output the raw feed\n",
    "            fop = frame\n",
    "\n",
    "        cv.imshow('Raw',frame)\n",
    "        cv.imshow('Processed',fop)\n",
    "\n",
    "        await client.sleep(0.001)\n",
    "        \n",
    "        # Close all windows and get out of the loop if ESC is pressed\n",
    "        if cv.waitKey(1) == 27:\n",
    "            cv.destroyAllWindows()\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MOBILEROBOTS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
